{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0d600413",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Protein-Ligand Binding Affinity Analysis Script (Time-stamped)\n",
    "------------------------------------------------\n",
    "Description:\n",
    "    This script automates the analysis of Microscale Thermophoresis (MST) \n",
    "    or similar binding affinity data. It processes CSV files in the current \n",
    "    directory, calculates binding kinetics using a one-site binding model, \n",
    "    and generates fitted plots.\n",
    "\n",
    "    * Feature: Creates a unique output folder based on current time (HH:MM:SS)\n",
    "      to prevent overwriting previous results.\n",
    "\n",
    "    If outliers are marked in the raw data (column 'Is Outlier'), \n",
    "    the script performs analysis twice:\n",
    "    1. Clean Data (Outliers excluded) - Primary Analysis\n",
    "    2. All Data (Outliers included) - For validation/transparency\n",
    "\n",
    "Author: [hanbyeonggu@gmail.com/BCK Lab]\n",
    "Date: 2025-12-09\n",
    "Dependencies: pandas, matplotlib, numpy, scipy\n",
    "\"\"\"\n",
    "\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from scipy.optimize import curve_fit\n",
    "import os\n",
    "import glob\n",
    "import datetime\n",
    "import warnings\n",
    "\n",
    "# Suppress runtime warnings (e.g., division by zero during optimization steps)\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# ---------------------------------------------------------\n",
    "# [Configuration] Parameters & Constants\n",
    "# ---------------------------------------------------------\n",
    "INPUT_FILE_EXT = \"*.csv\"\n",
    "MAX_FILES_TO_PROCESS = 100\n",
    "DELIMITER = ';'  # Adjust if your CSV uses commas (',')\n",
    "\n",
    "# Column Mapping (Adjust these if raw data headers change)\n",
    "COL_CONC = 'Ligand Concentration [M]'\n",
    "COL_FNORM = 'Fnorm [‰]'\n",
    "COL_OUTLIER = 'Is Outlier'\n",
    "\n",
    "# ---------------------------------------------------------\n",
    "# [Functions] Mathematical Models & Plotting\n",
    "# ---------------------------------------------------------\n",
    "\n",
    "def one_site_binding_model(x, kd, bottom, top):\n",
    "    \"\"\"\n",
    "    Standard Langmuir isotherm equation for 1:1 binding.\n",
    "    Formula: y = bottom + (top - bottom) * (x / (Kd + x))\n",
    "    \"\"\"\n",
    "    return bottom + (top - bottom) * (x / (kd + x))\n",
    "\n",
    "def perform_fitting_and_plotting(df_stats, save_path, label_suffix=\"\"):\n",
    "    \"\"\"\n",
    "    Performs non-linear least squares fitting and generates a publication-quality plot.\n",
    "    \"\"\"\n",
    "    x_data = df_stats['Conc'].values\n",
    "    y_data = df_stats['Mean'].values\n",
    "    y_err = df_stats['Std'].values\n",
    "\n",
    "    # 1. Parameter Estimation (Levenberg-Marquardt algorithm)\n",
    "    try:\n",
    "        # Dynamic initial guess for robustness:\n",
    "        # Kd guess = median of concentrations\n",
    "        # Bottom/Top guess = min/max of observed signals\n",
    "        p0_guess = [np.median(x_data), np.min(y_data), np.max(y_data)]\n",
    "        \n",
    "        popt, pcov = curve_fit(one_site_binding_model, x_data, y_data, p0=p0_guess, maxfev=10000)\n",
    "        kd_val, bottom_val, top_val = popt\n",
    "        \n",
    "        # Calculate R-squared (R2)\n",
    "        residuals = y_data - one_site_binding_model(x_data, *popt)\n",
    "        ss_res = np.sum(residuals**2)\n",
    "        ss_tot = np.sum((y_data - np.mean(y_data))**2)\n",
    "        r2 = 1 - (ss_res / ss_tot)\n",
    "        fit_success = True\n",
    "    except Exception as e:\n",
    "        print(f\"    [!] Fitting failed for {label_suffix}: {e}\")\n",
    "        kd_val, r2 = 0, 0\n",
    "        fit_success = False\n",
    "\n",
    "    # 2. Plotting\n",
    "    plt.rcParams['font.family'] = 'sans-serif'\n",
    "    plt.rcParams['font.sans-serif'] = ['Arial', 'Helvetica']\n",
    "    plt.rcParams['font.size'] = 12\n",
    "    \n",
    "    fig, ax = plt.subplots(figsize=(6, 5))\n",
    "\n",
    "    # Plot Raw Data points with Error bars\n",
    "    ax.errorbar(x_data, y_data, yerr=y_err, fmt='o', color='black', ecolor='gray', \n",
    "                capsize=4, label='Experimental Data', zorder=3)\n",
    "\n",
    "    # Plot Fit Curve\n",
    "    if fit_success:\n",
    "        x_fit = np.logspace(np.log10(min(x_data)/2), np.log10(max(x_data)*2), 1000)\n",
    "        y_fit = one_site_binding_model(x_fit, *popt)\n",
    "        ax.plot(x_fit, y_fit, color='#D32F2F', linewidth=2.5, label='Langmuir Fit', zorder=2)\n",
    "        \n",
    "        # Annotation Box\n",
    "        txt = f'$K_d$ = {kd_val*1e9:.1f} nM\\n$R^2$ = {r2:.4f}'\n",
    "        ax.text(0.95, 0.95, txt, transform=ax.transAxes, verticalalignment='top', \n",
    "                horizontalalignment='right', \n",
    "                bbox=dict(boxstyle='round,pad=0.4', facecolor='white', alpha=0.9, edgecolor='lightgray'))\n",
    "\n",
    "    ax.set_xscale('log')\n",
    "    ax.set_xlabel('Ligand Concentration [M]', fontweight='bold')\n",
    "    ax.set_ylabel('Fnorm [‰]', fontweight='bold')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    \n",
    "    # Save Figures\n",
    "    plt.savefig(f\"{save_path}.png\", dpi=300)\n",
    "    plt.savefig(f\"{save_path}.svg\", format='svg')\n",
    "    plt.close()\n",
    "    print(f\"    -> Graph Saved: {os.path.basename(save_path)}.png\")\n",
    "\n",
    "# ---------------------------------------------------------\n",
    "# [Main] Batch Processing Logic\n",
    "# ---------------------------------------------------------\n",
    "def main():\n",
    "    # 1. Setup Output Directory with Timestamp (Prevents Overwriting)\n",
    "    # Format: Analysis_MMDD_HHMMSS (e.g., Analysis_1209_143005)\n",
    "    timestamp_str = datetime.datetime.now().strftime(\"%m%d_%H%M%S\")\n",
    "    output_dir = os.path.join(os.getcwd(), f\"Analysis_{timestamp_str}\")\n",
    "    \n",
    "    if not os.path.exists(output_dir):\n",
    "        os.makedirs(output_dir)\n",
    "        print(f\">>> Created Output Directory: {output_dir}\")\n",
    "    \n",
    "    # 2. Find CSV Files\n",
    "    file_list = glob.glob(INPUT_FILE_EXT)\n",
    "    file_list = [f for f in file_list if \"Processed\" not in f] # Avoid re-processing output files\n",
    "    \n",
    "    if not file_list:\n",
    "        print(\">>> No CSV files found in the current directory.\")\n",
    "        return\n",
    "\n",
    "    print(f\">>> Found {len(file_list)} files. Processing up to {MAX_FILES_TO_PROCESS}...\")\n",
    "\n",
    "    # 3. Process Files\n",
    "    for i, filepath in enumerate(file_list[:MAX_FILES_TO_PROCESS]):\n",
    "        filename = os.path.basename(filepath)\n",
    "        base_name = os.path.splitext(filename)[0]\n",
    "        print(f\"\\n[{i+1}] Processing: {filename}\")\n",
    "\n",
    "        try:\n",
    "            df = pd.read_csv(filepath, delimiter=DELIMITER)\n",
    "        except Exception as e:\n",
    "            print(f\"    [Error] Could not read file: {e}\")\n",
    "            continue\n",
    "\n",
    "        # Validation: Check Columns\n",
    "        if COL_CONC not in df.columns or COL_FNORM not in df.columns:\n",
    "            print(f\"    [Skip] Missing essential columns.\")\n",
    "            continue\n",
    "\n",
    "        # -----------------------------------------------------\n",
    "        # Analysis Workflow\n",
    "        # -----------------------------------------------------\n",
    "        \n",
    "        # Check if Outliers exist in the dataset\n",
    "        has_outliers = False\n",
    "        if COL_OUTLIER in df.columns:\n",
    "            if df[COL_OUTLIER].eq(True).any() or df[COL_OUTLIER].eq(1).any():\n",
    "                has_outliers = True\n",
    "\n",
    "        datasets_to_process = []\n",
    "\n",
    "        # A. Prepare Clean Data (Standard)\n",
    "        if COL_OUTLIER in df.columns:\n",
    "            df_clean = df[df[COL_OUTLIER] != True] # Exclude outliers\n",
    "        else:\n",
    "            df_clean = df # No outlier column, treat all as clean\n",
    "        datasets_to_process.append(('Clean', df_clean))\n",
    "\n",
    "        # B. Prepare All Data (Only if outliers detected)\n",
    "        if has_outliers:\n",
    "            datasets_to_process.append(('AllData_with_Outliers', df))\n",
    "            print(\"    -> [Info] Outliers detected. Comparing 'Clean' vs 'All Data'.\")\n",
    "\n",
    "        # C. Iterate through datasets (Clean vs All), Save CSV, and Plot\n",
    "        for label, data_subset in datasets_to_process:\n",
    "            if data_subset.empty:\n",
    "                continue\n",
    "\n",
    "            # 1. Calculate Statistics (Mean & Std per concentration)\n",
    "            stats = data_subset.groupby(COL_CONC)[COL_FNORM].agg(['mean', 'std']).reset_index()\n",
    "            stats.columns = ['Conc', 'Mean', 'Std']\n",
    "            \n",
    "            # 2. Save Processed Data to CSV (For transparency/submission)\n",
    "            save_name = f\"{base_name}_{label}_Processed.csv\"\n",
    "            save_path_csv = os.path.join(output_dir, save_name)\n",
    "            stats.to_csv(save_path_csv, index=False)\n",
    "            \n",
    "            # 3. Generate Graph\n",
    "            save_path_plot = os.path.join(output_dir, f\"{base_name}_{label}_Plot\")\n",
    "            perform_fitting_and_plotting(stats, save_path_plot, label_suffix=label)\n",
    "\n",
    "    print(f\"\\n>>> Batch processing completed. Results saved in: {output_dir}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
